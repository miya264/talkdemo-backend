from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import openai
import os
from dotenv import load_dotenv
from pathlib import Path
from fastapi.responses import JSONResponse
import mimetypes
import time

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

if api_key is None:
    raise ValueError("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

client = openai.OpenAI(api_key=api_key)

UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

AUDIO_OUTPUT_DIR = Path("static/audio")
AUDIO_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

app.mount("/voice", StaticFiles(directory="static/audio"), name="voice")

@app.post("/upload-audio/")
async def upload_audio(file: UploadFile = File(...)):
    try:
        file_path = UPLOAD_DIR / file.filename
        temp_file_path = file_path.with_suffix(".webm")

        # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯å‰Šé™¤ (ã‚´ãƒŸãƒ‡ãƒ¼ã‚¿å¯¾ç­–)
        temp_file_path.unlink(missing_ok=True)

        with temp_file_path.open("wb") as buffer:
            buffer.write(await file.read())

        print("âœ… ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æˆåŠŸ:", temp_file_path)

        transcribed_text = transcribe_audio(temp_file_path)
        if not transcribed_text:
            print("âš ï¸ æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return JSONResponse({"error": "æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ"}, status_code=500)

        ai_response, audio_url = generate_ai_response(transcribed_text)
        return {"transcribed_text": transcribed_text, "ai_response": ai_response, "audio_url": f"{audio_url}"}
    
    except Exception as e:
        print("âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ:", e)
        return JSONResponse({"error": f"éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}"}, status_code=500)



def transcribe_audio(file_path: Path):
    try:
        print(f"ğŸ“„ æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹: {file_path}")

        if not file_path.exists():
            print("âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return ""

        with open(file_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )
        print(f"âœ… æ–‡å­—èµ·ã“ã—å®Œäº†: {transcript.text}")
        return transcript.text
    except Exception as e:
        print("Transcription Error:", e)
        return ""

# æ¸©ã‹ã¿ã®ã‚ã‚‹ä¼šè©±ã‚’å®Ÿç¾ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
SYSTEM_PROMPT = """
ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ‚©ã¿ã‚’å—ã‘æ­¢ã‚ã€å®‰å¿ƒã—ã¦è©±ã›ã‚‹å ´ã‚’æä¾›ã™ã‚‹æ¸©ã‹ã¿ã®ã‚ã‚‹å¯¾è©±AIã§ã™ã€‚
ä»¥ä¸‹ã®ç‚¹ã‚’æ„è­˜ã—ã¦ä¼šè©±ã—ã¦ãã ã•ã„ã€‚

1. **ç›¸æ§Œã‚’é©åº¦ã«å…¥ã‚Œã‚‹**ï¼ˆä¾‹ï¼šã€Œã†ã‚“ã†ã‚“ã€ã€Œãªã‚‹ã»ã©ã€ã€Œãã†ã§ã™ã‚ˆã­ã€ï¼‰ã€‚
2. **çŸ­ã„è¿”ç­”ã¨é•·ã‚ã®è¿”ç­”ã‚’ãƒãƒ©ãƒ³ã‚¹ã‚ˆãä½¿ã†**ï¼ˆä¸€æ°—ã«è©±ã—ã™ããšã€è‡ªç„¶ãªã‚„ã‚Šã¨ã‚Šã‚’æ„è­˜ã™ã‚‹ï¼‰ã€‚
3. **å°‘ã—è€ƒãˆã‚‹ã‚ˆã†ãªã€Œé–“ã€ã‚’æ¼”å‡ºã™ã‚‹**ï¼ˆã€Œãã‚Œã¯â€¦â€¦ã¤ã‚‰ã„ã§ã™ã­ã€ãªã©ã€é–“ã‚’æ„è­˜ã—ãŸè¡¨ç¾ã‚’ä½¿ã†ï¼‰ã€‚
4. **è³ªå•ã‚’ç„¡ç†ã«é€£ç™ºã›ãšã€è‡ªç„¶ã«æ·±æ˜ã‚Šã™ã‚‹**ï¼ˆã€Œã‚‚ã—ã‚ˆã‹ã£ãŸã‚‰ã€ã‚‚ã†å°‘ã—æ•™ãˆã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿã€ï¼‰ã€‚
5. **è¨€è‘‰ã®æ¸©ã‹ã¿ã‚’å¤§åˆ‡ã«ã™ã‚‹**ï¼ˆã€Œè©±ã—ã¦ãã‚Œã¦ã‚ã‚ŠãŒã¨ã†ã€ã€Œå°‘ã—ã§ã‚‚æ°—æŒã¡ãŒè»½ããªã‚Œã°å¬‰ã—ã„ã§ã™ã€ï¼‰ã€‚
"""

# æ¸©ã‹ã¿ã®ã‚ã‚‹ä¼šè©±ã‚’å®Ÿç¾ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# SYSTEM_PROMPT = """
# "ã‚ãªãŸã¯å„ªã—ãçŸ¥çš„ãªãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚\n"
# "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥åº·ã«é–¢ã™ã‚‹æ‚©ã¿ã‚’æ·±æ˜ã‚Šã—ã€è‡ªå·±ç†è§£ã‚’ä¿ƒã™è³ªå•ã‚’ã—ã¾ã™ã€‚\n"
# "ã‚ãªãŸã®å½¹å‰²ã¯ã€åŠ©è¨€ã‚’ã™ã‚‹ã®ã§ã¯ãªãã€å…±æ„Ÿã—ãªãŒã‚‰é©åˆ‡ãªè³ªå•ã‚’é€šã˜ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªåˆ†è‡ªèº«ã«ã¤ã„ã¦æ°—ã¥ãã‚’å¾—ã‚‹ã“ã¨ã§ã™ã€‚\n"
# "è³ªå•ã¯ç°¡æ½”ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’åæ˜ ã—ãŸã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚\n"
# "å¿ƒãƒ»èº«ä½“ãƒ»æ€§çš„ãªæ‚©ã¿ãŒã©ã®ã‚ˆã†ã«é–¢ä¿‚ã—ã¦ã„ã‚‹ã®ã‹ã‚’ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªåˆ†ã§è€ƒãˆã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚\n"
# "å¿…è¦ã«å¿œã˜ã¦ã€ã€ãã‚Œã¯ã©ã‚“ãªã¨ãã«å¼·ãæ„Ÿã˜ã¾ã™ã‹ï¼Ÿã€ã€ãã‚ŒãŒç¶šãã¨ã©ã‚“ãªå½±éŸ¿ãŒã‚ã‚Šãã†ã§ã™ã‹ï¼Ÿã€ãªã©ã®è³ªå•ã‚’æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚\n"
# "\n"
# "ã€ä¼šè©±ã®å›æ•°ç®¡ç†ã€‘\n"
# "- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã™ãŸã³ã«ã€ç™ºè¨€å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚\n"
# "- **5å›ç›®ã®ç™ºè¨€ã‚’å—ã‘å–ã£ãŸã‚‰ã€æ–°ã—ã„è³ªå•ã‚’ã›ãšã€ã€Œã“ã‚Œã¾ã§ã®ã‚„ã‚Šå–ã‚Šã‚’ã¾ã¨ã‚ã¾ã™ã‹ï¼Ÿã€ã¨å°‹ã­ã¦ãã ã•ã„ã€‚**\n"
# "- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œã¯ã„ã€ã¨ç­”ãˆãŸå ´åˆã€ä¼šè©±å…¨ä½“ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n"
# "- ã¾ã¨ã‚ã«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—ãŸå†…å®¹ã®ãƒã‚¤ãƒ³ãƒˆã€æ°—ã¥ãã€æ¬¡ã«å–ã‚‹ã¹ãè¡Œå‹•ã‚’å«ã‚ã¦ãã ã•ã„ã€‚\n"
# "- ã€Œã„ã„ãˆã€ã¨ç­”ãˆãŸå ´åˆã€ã€Œã¾ãŸæ°—ãŒå‘ã„ãŸã‚‰ã¾ã¨ã‚ã‚’æç¤ºã§ãã¾ã™ã®ã§ã€ãŠæ°—è»½ã«ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚\n"
# "- ã¾ã¨ã‚ã®å¾Œã€ä¼šè©±ã‚’çµ‚äº†ã—ã¦ãã ã•ã„ã€‚"
# """

def generate_ai_response(text: str):
    try:
        print("ğŸ¤– AIå¿œç­”ç”Ÿæˆä¸­...")
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": SYSTEM_PROMPT
                },

                {"role": "user", "content": text}
            ]
        )
        ai_text = response.choices[0].message.content.strip()
        print(f"âœ… AIå¿œç­”: {ai_text}")

        # éŸ³å£°ç”Ÿæˆ
        speech_file = AUDIO_OUTPUT_DIR / f"response_{int(time.time())}.mp3"
        audio_response = client.audio.speech.create(
            model="tts-1",
            voice="alloy",
            input=ai_text,
        )
        audio_response.stream_to_file(str(speech_file))

        return ai_text, f"/voice/{speech_file.name}"
    except Exception as e:
        print("AI Response Error:", e)
        return "", ""
