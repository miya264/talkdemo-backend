from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import openai
import os
from dotenv import load_dotenv
from pathlib import Path
from fastapi.responses import JSONResponse
import mimetypes
import time

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

if api_key is None:
    raise ValueError("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

client = openai.OpenAI(api_key=api_key)

UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

AUDIO_OUTPUT_DIR = Path("static/audio")
AUDIO_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

app.mount("/voice", StaticFiles(directory="static/audio"), name="voice")

@app.post("/upload-audio/")
async def upload_audio(file: UploadFile = File(...)):
    print(f"ğŸ“¤ å—ä¿¡ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«å: {file.filename}")
    print(f"ğŸ“¤ å—ä¿¡ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—: {file.content_type}")

    try:
        file_path = UPLOAD_DIR / file.filename

        with file_path.open("wb") as buffer:
            buffer.write(await file.read())

        print("âœ… ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æˆåŠŸ:", file_path)

        mime_type, _ = mimetypes.guess_type(str(file_path))
        print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ« MIME ã‚¿ã‚¤ãƒ—: {mime_type}")

        transcribed_text = transcribe_audio(file_path)
        if not transcribed_text:
            print("âš ï¸ æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return JSONResponse({"error": "æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ"}, status_code=500)

        ai_response, audio_url = generate_ai_response(transcribed_text)
        
        return {"transcribed_text": transcribed_text, "ai_response": ai_response, "audio_url": f"{audio_url}"}

    except Exception as e:
        print("âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ:", e)
        return JSONResponse({"error": f"éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}"}, status_code=500)

def transcribe_audio(file_path: Path):
    try:
        print(f"ğŸ“„ æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹: {file_path}")

        if not file_path.exists():
            print("âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return ""

        with open(file_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )

        print(f"âœ… æ–‡å­—èµ·ã“ã—å®Œäº†: {transcript.text}")
        return transcript.text
    except Exception as e:
        print("Transcription Error:", e)
        return ""

def generate_ai_response(text: str):
    try:
        print("ğŸ¤– AIå¿œç­”ç”Ÿæˆä¸­...")
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": (
                    "ã‚ãªãŸã¯å„ªã—ãçŸ¥çš„ãªãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚\n"
                    "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥åº·ã«é–¢ã™ã‚‹æ‚©ã¿ã‚’æ·±æ˜ã‚Šã—ã€è‡ªå·±ç†è§£ã‚’ä¿ƒã™è³ªå•ã‚’ã—ã¾ã™ã€‚\n"
                    "ã‚ãªãŸã®å½¹å‰²ã¯ã€åŠ©è¨€ã‚’ã™ã‚‹ã®ã§ã¯ãªãã€å…±æ„Ÿã—ãªãŒã‚‰é©åˆ‡ãªè³ªå•ã‚’é€šã˜ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªåˆ†è‡ªèº«ã«ã¤ã„ã¦æ°—ã¥ãã‚’å¾—ã‚‹ã“ã¨ã§ã™ã€‚\n"
                    "è³ªå•ã¯ç°¡æ½”ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’åæ˜ ã—ãŸã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚\n"
                    "å¿ƒãƒ»èº«ä½“ãƒ»æ€§çš„ãªæ‚©ã¿ãŒã©ã®ã‚ˆã†ã«é–¢ä¿‚ã—ã¦ã„ã‚‹ã®ã‹ã‚’ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªåˆ†ã§è€ƒãˆã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚\n"
                    "å¿…è¦ã«å¿œã˜ã¦ã€ã€ãã‚Œã¯ã©ã‚“ãªã¨ãã«å¼·ãæ„Ÿã˜ã¾ã™ã‹ï¼Ÿã€ã€ãã‚ŒãŒç¶šãã¨ã©ã‚“ãªå½±éŸ¿ãŒã‚ã‚Šãã†ã§ã™ã‹ï¼Ÿã€ãªã©ã®è³ªå•ã‚’æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚\n"
                    "æœ€å¤§5å¾€å¾©ã§çµ‚äº†ã™ã‚‹ã‚ˆã†ã«èª¿æ•´ã—ã¦ãã ã•ã„ã€‚"
                )},
                {"role": "user", "content": text}
            ]
        )
        ai_text = response.choices[0].message.content.strip()
        print(f"âœ… AIå¿œç­”: {ai_text}")

        # éŸ³å£°ç”Ÿæˆ
        speech_file = AUDIO_OUTPUT_DIR / f"response_{int(time.time())}.mp3"
        audio_response = client.audio.speech.create(
            model="tts-1",
            voice="alloy",
            input=ai_text,
        )
        audio_response.stream_to_file(str(speech_file))

        return ai_text, f"/voice/{speech_file.name}"
    except Exception as e:
        print("AI Response Error:", e)
        return "", ""
